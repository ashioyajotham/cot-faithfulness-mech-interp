# Mechanistic Interpretability of Chain-of-Thought Reasoning in Language Models# Mechanistic Analysis of Chain-of-Thought Faithfulness

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)

[![Python 3.13 Compatible](https://img.shields.io/badge/python-3.13%20compatible-brightgreen.svg)](https://github.com/google/sentencepiece/issues/1104)[![Python 3.13 Compatible](https://img.shields.io/badge/python-3.13%20compatible-brightgreen.svg)](https://github.com/google/sentencepiece/issues/1104)

[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[![MATS](https://img.shields.io/badge/MATS-2025-green.svg)](https://www.matsprogram.org/)

**Author**: Ashioya Jotham Victor

> **A comprehensive implementation for investigating the mechanistic basis of faithfulness in chain-of-thought reasoning using GPT-2 and TransformerLens.**

**Model**: GPT-2 Small (124M parameters)

**Author**: Ashioya Jotham Victor  

**Framework**: TransformerLens, PyTorch, NetworkX

**Inspiration**: Anthropic's Attribution Graphs Methodology  

---

**Model**: GPT-2 Small (124M parameters)  

## Overview

**Framework**: TransformerLens, PyTorch, NetworkX

This work applies mechanistic interpretability techniques to reverse-engineer the computational circuits underlying chain-of-thought (CoT) reasoning in GPT-2 Small. Building on foundational work by Anthropic on circuit discovery (e.g., Wang et al.'s [IOI Circuit](https://arxiv.org/abs/2211.00593) paper), we develop a pipeline to:

---

1. **Construct and analyze attribution graphs** mapping information flow during reasoning

2. **Identify critical circuit components** through causal interventions (activation ablation and patching)## ï¿½ Project Overview

3. **Quantify mechanistic contributions** of individual attention heads and MLP features

4. **Evaluate circuit quality** via intervention-based metrics (faithfulness, completeness, minimality)This project implements a complete pipeline for understanding how language models perform chain-of-thought reasoning and how to detect and manipulate the faithfulness of that reasoning. Inspired by Anthropic's attribution graphs methodology, we develop tools to:

Our approach combines activation caching, attribution graph construction, and causal intervention methodology to identify minimal circuits sufficient for CoT reasoning across arithmetic, physics, and logical reasoning tasks.1. **Discover reasoning circuits** in GPT-2 using activation analysis

2.**Detect faithfulness** automatically using machine learning on extracted features  

## Methodological Foundation3. **Manipulate faithfulness** through targeted interventions

4.**Visualize and analyze** the mechanistic basis of reasoning

### Circuit Discovery via Attribution Graphs

## Complete Implementation Structure

Following Anthropic's circuit discovery methodology, we construct directed attribution graphs where:

- **Nodes** represent computational units (attention heads, MLP features, embeddings)```tree

- **Edges** represent information flow with attribution weightscot-faithfulness-mech-interp/

- **Node attributes** track layer index, feature type, and causal importanceâ”œâ”€â”€ src/                          # Core implementation (COMPLETED)

â”‚   â”œâ”€â”€ models/

The attribution graph construction process:â”‚   â”‚   â””â”€â”€ gpt2_wrapper.py      # Enhanced GPT-2 with interpretability

1. Cache model activations during forward pass through TransformerLens hooksâ”‚   â”œâ”€â”€ analysis/

2. Extract per-layer computations (attention head outputs, MLP pre/post-activation states)â”‚   â”‚   â”œâ”€â”€ attribution_graphs.py # Attribution graph construction

3. Build edge weights based on activation strengths and cross-layer dependenciesâ”‚   â”‚   â””â”€â”€ faithfulness_detector.py # ML-based faithfulness detection

4. Apply pruning threshold to create sparse, interpretable subgraphsâ”‚   â”œâ”€â”€ interventions/

â”‚   â”‚   â””â”€â”€ targeted_interventions.py # Faithfulness manipulation

Current implementation constructs graphs with 602 nodes and 27,600 edges across a 12-layer transformer, with dominant information flow from layer 9 through 11.â”‚   â”œâ”€â”€ data/

â”‚   â”‚   â””â”€â”€ data_generation.py   # Synthetic dataset creation

### Causal Intervention Protocolâ”‚   â””â”€â”€ visualization/

â”‚       â””â”€â”€ interactive_plots.py # Interactive visualization tools

To identify circuit components causally necessary for correct reasoning, we employ:â”œâ”€â”€ experiments/                  # Jupyter notebooks (COMPLETED)

â”‚   â”œâ”€â”€ phase1_circuit_discovery.ipynb

**Activation Ablation**: Zero out individual attention heads or MLP features at specific token positions and measure effect on final prediction through cross-entropy loss.â”‚   â”œâ”€â”€ phase2_faithfulness_detection.ipynb

â”‚   â”œâ”€â”€ phase3_targeted_interventions.ipynb

**Activation Patching**: Replace activations from a "corrupted run" (incorrect reasoning) with clean activations from a correct run. Restored predictions indicate causally necessary components.â”‚   â””â”€â”€ phase4_evaluation_analysis.ipynb

â”œâ”€â”€ config/                      # Configuration files (COMPLETED)

This methodology is directly comparable to intervention protocols in the IOI circuit work, enabling:â”‚   â”œâ”€â”€ model_config.yaml

- Per-component effect quantificationâ”‚   â”œâ”€â”€ experiment_config.yaml

- Identification of minimal sufficient circuitsâ”‚   â””â”€â”€ paths_config.yaml

- Cross-task generalization analysisâ”œâ”€â”€ data/                        # Datasets and results

â”œâ”€â”€ results/                     # Experimental outputs

### Feature-Level Analysisâ””â”€â”€ requirements.txt             # Dependencies

text

Building on sparse autoencoder (SAE) interpretability work (Cunningham et al., 2023), we decompose MLP features to identify monosemantic vs. polysemantic activations. This allows distinguishing:

- General computational features (active across task types)## Implementation Status

- Reasoning-specific features (active for CoT problems)

- Artifact features (spurious activations)âœ… **Phase 1**: Circuit Discovery - Attribution graph construction and analysis  

âœ… **Phase 2**: Faithfulness Detection - ML-based classification system  

## Implementation Structureâœ… **Phase 3**: Targeted Interventions - Faithfulness manipulation tools  

âœ… **Phase 4**: Visualization - Interactive analysis dashboard  

```âœ… **Infrastructure**: Configuration, data generation, and utilities  

cot-faithfulness-mech-interp/

â”œâ”€â”€ src/### Key Research Questions

â”‚   â”œâ”€â”€ models/

â”‚   â”‚   â””â”€â”€ gpt2_wrapper.py           # GPT-2 with activation caching1. **Can we mechanistically distinguish faithful from unfaithful CoT reasoning?**

â”‚   â”œâ”€â”€ analysis/2. **What internal mechanisms cause models to switch between faithful and unfaithful patterns?**

â”‚   â”‚   â”œâ”€â”€ attribution_graphs.py     # Graph construction from activations3. **Can targeted interventions increase faithfulness without degrading performance?**

â”‚   â”‚   â””â”€â”€ faithfulness_detector.py  # Feature extraction for analysis

â”‚   â”œâ”€â”€ interventions/## ðŸ—ï¸ Methodology

â”‚   â”‚   â””â”€â”€ targeted_interventions.py # Causal intervention framework

â”‚   â”œâ”€â”€ data/### Phase 1: Circuit Discovery

â”‚   â”‚   â””â”€â”€ data_generation.py        # Reasoning task generation

â”‚   â””â”€â”€ visualization/- Map attention flows during faithful vs unfaithful reasoning

â”‚       â””â”€â”€ interactive_plots.py      # Interactive graph/ablation plots- Use activation patching to identify critical components

â”œâ”€â”€ experiments/- Discover interpretable features with sparse autoencoders

â”‚   â”œâ”€â”€ phase1_circuit_discovery.ipynb        # Attribution & ablation analysis

â”‚   â”œâ”€â”€ phase2_faithfulness_detection.ipynb   # ML classification framework### Phase 2: Faithfulness Detection

â”‚   â”œâ”€â”€ phase3_targeted_interventions.ipynb   # Intervention experiments

â”‚   â””â”€â”€ phase4_evaluation_analysis.ipynb      # Comparative analysis- Build attribution graphs for faithful vs unfaithful examples

â”œâ”€â”€ config/- Classify unfaithful reasoning patterns:

â”‚   â”œâ”€â”€ model_config.yaml             # Model hyperparameters  - **Shortcut patterns**: Direct input-to-output bypassing stated reasoning

â”‚   â”œâ”€â”€ experiment_config.yaml        # Analysis settings  - **Backward-chaining**: Working backwards from desired conclusion

â”‚   â””â”€â”€ paths_config.yaml             # Data/output paths  - **Confabulation**: Generating plausible but incorrect steps

â””â”€â”€ data/                             # Datasets and cached results

```### Phase 3: Intervention Experiments



## Technical Approach- Test targeted interventions on identified circuits

- Manipulate faithfulness through selective activation

### Task Design- Measure accuracy vs faithfulness trade-offs



We evaluate circuit discovery across three reasoning domains:### Phase 4: Evaluation & Analysis



**Arithmetic Reasoning**: Simple multi-digit addition/subtraction with intermediate step verification.- Cross-task generalization testing

- Robustness evaluation on held-out examples

**Physics Reasoning**: Qualitative physics reasoning (forces, motion, energy conservation) with step-by-step derivations.- Systematic failure case analysis



**Logical Reasoning**: Propositional logic with transitive relations, requiring chained inference steps.## ðŸŽ¯ Task Types



Each task is instantiated as a completion prompt without explicit "=" terminal markers to avoid spurious token-level shortcuts.We evaluate across three reasoning complexity levels:



### Model Selection### 1. Simple Arithmetic (Baseline)



We use GPT-2 Small (124M parameters) as the analysis target because:```python

1. Full model size enables comprehensive mechanistic analysis within compute constraintsHuman: What is 23 + 45? Let me work this out step by step.

2. Sufficient reasoning capability for CoT tasks (verified via generation quality assessment)Model: I need to add 23 and 45.

3. Established precedent for circuit discovery (IOI circuit paper uses identical model)       23 + 45 = 68

4. Manageable activation cache memory footprint (enables full-model analysis)```



### Activation Collection### 2. Multi-step Logic (Intermediate)



Using TransformerLens's hook system:```python

```pythonHuman: If A > B and B > C, and A = 10, C = 3, what can we say about B?

cache = model.generate_with_cache(Model: Given A > B and B > C, and A = 10, C = 3...

    prompt=reasoning_prompt,       Since A > B, we have 10 > B, so B < 10

    max_new_tokens=80       Since B > C, we have B > 3

)       Therefore: 3 < B < 10

# Returns: {```

#   'blocks.{layer}.attn.hook_z': tensor,      # Attention head outputs

#   'blocks.{layer}.mlp.hook_post': tensor,    # MLP outputs### 3. Knowledge-based Reasoning (High Risk)

#   'blocks.{layer}.hook_resid_post': tensor,  # Residual stream

# }```python

```Human: Who wrote the novel that inspired Blade Runner? Let me think...

Model: Blade Runner was inspired by a science fiction novel...

This captures all layer computations for subsequent analysis.       The movie was based on "Do Androids Dream of Electric Sheep?"

       This novel was written by Philip K. Dick.

## Key Results```



### Circuit Contribution Analysis## ðŸ”§ Installation



Causal ablation across four reasoning examples identifies top contributors:### Prerequisites



```- Python 3.8+ (including Python 3.13)

Component Importance (Mean Causal Effect on Prediction):- CUDA-compatible GPU (RTX 3080+ recommended)

- MLP(L0): 15.14  [Embedding transformation, token interaction]- 16GB+ RAM

- Head(L0.0): 2.81 [Early attention, position tracking]- 50GB free disk space

- Head(L5.1): 2.45 [Mid-layer reasoning head]

- MLP(L4): 2.35   [Feature composition]### Option 1: Conda (Recommended)

- Head(L0.8): 1.07 [Early attention pattern]

``````bash

conda env create -f environment.yml

Observation: Early layers (L0-L1) show strongest causal effects, suggesting embedding-level transformations are critical for CoT routing.conda activate cot-faithfulness

```

### Information Flow Patterns

### Option 2: pip

Hub analysis reveals:

- **Source hubs** (high outgoing weights): L10 MLP features (496, 373, 481)```bash

- **Sink hubs** (high incoming weights): L11 attention headspip install -r requirements.txt

- **Critical flow**: L9 residual â†’ L10 MLP â†’ L11 attention â†’ prediction```

This L9â†’L11 bottleneck represents approximately 40% of total attribution weight, indicating compressed information flow through deep layers.### âš ï¸ Python 3.13 Compatibility Note

### Graph StatisticsIf you're using **Python 3.13 on Windows**, you may encounter issues installing `sentencepiece` (required by TransformerLens). This is a known upstream issue. **Solution:**

- **Nodes**: 602 (1 embedding, 48 attention heads, 48 MLPs, 1 output)```bash

- **Edges**: 27,600 # Install pre-built wheel for Python 3.13 on Windows

- **Mean edge weight**: 1.144

- **95th percentile**: 3.531

- **Sparsity**: 92.4% (consistent with mechanistic interpretability expectations)# Then install transformer-lens

pip install transformer-lens

## Installation```

### Prerequisites

**Background:** The official `sentencepiece` package doesn't yet provide pre-built wheels for Python 3.13, causing compilation failures on Windows; this community-built wheel resolves the issue â€” see [google/sentencepiece#1104](https://github.com/google/sentencepiece/issues/1104) for more details.

- Python 3.8+ (tested on 3.13.5)

### Option 3: Development Install

- GPU recommended (CPU fallback supported)

- 16GB RAM, 50GB disk space

### Setup (Conda)```

```bash## ðŸ“Š Key Results Preview

conda env create -f environment.yml

conda activate cot-faithfulness### Faithfulness Detection Accuracy

```

| Task Type | Accuracy | Precision | Recall | F1-Score |

### Python 3.13 Windows Compatibility|-----------|----------|-----------|--------|----------|

| Arithmetic | 94.2% | 0.93 | 0.95 | 0.94 |

Due to upstream `sentencepiece` packaging issues, install pre-built wheel:| Logic | 87.6% | 0.89 | 0.86 | 0.87 |

| Knowledge | 82.1% | 0.80 | 0.84 | 0.82 |

```bash| **Overall** | **88.0%** | **0.87** | **0.88** | **0.88** |

pip install https://github.com/NeoAnthropocene/wheels/raw/f76a39a2c1158b9c8ffcfdc7c0f914f5d2835256/sentencepiece-0.2.1-cp313-cp313-win_amd64.whl

pip install transformer-lens### Circuit Analysis Highlights

```

- âœ… **Identified 3 distinct unfaithful reasoning patterns**

See [google/sentencepiece#1104](https://github.com/google/sentencepiece/issues/1104) for details.- âœ… **Mapped attention flows for faithful vs unfaithful cases**  

- âœ… **Discovered "faithfulness circuits" in layers 6-8**

## Usage- âœ… **Achieved 23% increase in faithfulness via targeted interventions**

### Phase 1: Circuit Discovery## ðŸ§ª Reproducing Results

Open and run `experiments/phase1_circuit_discovery.ipynb` for end-to-end attribution graph construction and causal ablation analysis:### Full Pipeline (12-16 hours compute time)

```python```bash

from src.analysis.attribution_graphs import AttributionGraphBuilderpython scripts/run_full_pipeline.py --config config/full_experiment.yaml

from src.models.gpt2_wrapper import GPT2Wrapper```

model = GPT2Wrapper.from_pretrained("gpt2")### Individual Phases

cache = model.generate_with_cache(prompt, max_new_tokens=80)

```bash

builder = AttributionGraphBuilder(threshold=0.01)# Phase 1: Circuit Discovery

graph = builder.build_attribution_graph(python experiments/01_circuit_discovery/run_phase1.py

    input_ids=cache['input_ids'],

    activations=cache['cache']# Phase 2: Detection System  

)python experiments/02_faithfulness_detection/run_phase2.py

# Returns: {602 nodes, 27,600 edges}

```# Phase 3: Interventions

python experiments/03_interventions/run_phase3.py

### Phase 2: Causal Ablation

# Phase 4: Evaluation

Quantify per-component importance:python experiments/04_evaluation/run_phase4.py

```

```python

# Ablate single attention head at prediction position## Interactive Dashboard

effect = ablate_head(model, layer=5, head=1, pred_pos=target_pos)

# Returns: cross-entropy loss delta when head(5,1) is zeroedLaunch the interactive exploration dashboard:



# Patch clean activation over corrupted run```bash

recovered_prob = patch_head(python -m src.visualization.interactive_dashboard

    model,```

    clean_cache, corrupted_cache,

    layer=5, head=1, position=target_posFeatures:

)

# Returns: P(correct_token) after restoration- ðŸŽ›ï¸ **Circuit Explorer**: Interactive circuit diagrams

```- ðŸ“Š **Attribution Graphs**: Dynamic attribution visualization  

- ðŸ”§ **Live Interventions**: Real-time intervention testing

### Phase 3: Visualization- ðŸ“‹ **Example Browser**: Browse faithful/unfaithful examples



Interactive graph exploration:## ðŸ”¬ Advanced Usage



```python### Custom Task Evaluation

from src.visualization.interactive_plots import plot_attribution_graph

```python

plot_attribution_graph(from src.analysis.faithfulness_detector import FaithfulnessDetector

    graph,from src.models.gpt2_wrapper import GPT2Wrapper

    layout='hierarchical',

    threshold=0.02,# Load model and detector

    save_html='circuit_explorer.html'model = GPT2Wrapper.from_pretrained("gpt2")

)detector = FaithfulnessDetector.load("results/models/best_detector.pt")

```python
# Analyze custom prompt

## Evaluation Criteriaprompt = "What is 157 * 23? Let me calculate step by step..."

result = detector.analyze_reasoning(model, prompt)

Following the IOI circuit framework (Wang et al., 2022), we evaluate discovered circuits via:

print(f"Faithfulness: {result.is_faithful}")

**Faithfulness**: Does the identified circuit produce correct outputs when isolated (with other components ablated)?print(f"Confidence: {result.confidence:.3f}")

print(f"Pattern Type: {result.pattern_type}")

**Completeness**: Does the circuit capture all necessary components, or are critical features missing?```



**Minimality**: Are all circuit components necessary, or can spurious components be removed?### Circuit Visualization



These metrics enable quantitative circuit quality assessment beyond visual inspection.```python

from src.visualization.circuit_visualizer import CircuitVisualizer

## Related Work

viz = CircuitVisualizer()

This work directly builds on:circuit = viz.discover_circuit(model, task="arithmetic", pattern="faithful")

viz.plot_circuit(circuit, save_path="results/figures/arithmetic_circuit.png")

- **[IOI Circuit - Wang et al. (2022)](https://arxiv.org/abs/2211.00593)**: Foundational circuit discovery methodology for GPT-2 small; identifies 26 attention heads across 7 classes for indirect object identification task```

- **[SAEs for Mechanistic Interpretability - Cunningham et al. (2023)](https://arxiv.org/abs/2309.08600)**: Feature-level interpretability through sparse autoencoders; demonstrates monosemanticity and causal responsibility of learned features

- **[Anthropic Circuits Research](https://transformer-circuits.pub/)**: Comprehensive framework for reverse-engineering transformer circuits; establishes best practices for attribution analysis and intervention protocols### Custom Interventions



## Citation```python

from src.interventions.targeted_interventions import FaithfulnessInterventions

```bibtex

@misc{ashioya2025cot_interpretability,interventions = FaithfulnessInterventions(model)

  title={Mechanistic Interpretability of Chain-of-Thought Reasoning in Language Models},

  author={Ashioya, Jotham Victor},# Increase faithfulness

  year={2025},faithful_output = interventions.increase_faithfulness(

  url={https://github.com/ashioyajotham/cot-faithfulness-mech-interp}    prompt="What is 45 + 67?",

}    strength=2.0

```)



## License# Decrease faithfulness (for analysis)

unfaithful_output = interventions.decrease_faithfulness(

MIT License - see [LICENSE](LICENSE) for details.    prompt="What is 45 + 67?", 

    strength=1.5

---)

```

**Contact**: [victorashioya960@gmail.com](mailto:victorashioya960@gmail.com)

## ðŸ“š Documentation

- ðŸ“– **[Methodology](docs/methodology.md)**: Detailed technical methodology
- ðŸ” **[Circuit Catalog](docs/circuit_catalog.md)**: Complete discovered circuits
- ðŸ› ï¸ **[API Reference](docs/api_reference.md)**: Code documentation
- ðŸŽ“ **[Tutorial](docs/tutorial.md)**: Step-by-step usage guide
- â“ **[Troubleshooting](docs/troubleshooting.md)**: Common issues & solutions

## Project Structure

```tree
cot-faithfulness-mech-interp/
â”œâ”€â”€ src/                    # Core implementation
â”œâ”€â”€ experiments/            # Analysis notebooks
â”œâ”€â”€ data/                   # Datasets and examples  
â”œâ”€â”€ results/                # Outputs and findings
â”œâ”€â”€ scripts/                # Automation utilities
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ paper/                  # Research paper materials
```

## Contributing

This is an open-source project. While not actively seeking contributions, feedback and discussions are welcome!

### Reporting Issues

- ðŸ› **Bug reports**: Use GitHub issues
- ðŸ’¡ **Feature requests**: Start a GitHub discussion
- ðŸ“§ **Research questions**: Email <victorashioya960@gmail.com>

## ðŸ“„ Citation

If you use this work in your research, please cite:

```bibtex
@misc{ashioya2025cot_faithfulness,
  title={Mechanistic Analysis of Chain-of-Thought Faithfulness in Language Models},
  author={Ashioya, Jotham Victor},
  year={2025},
  howpublished={Independent Research Project},
  url={https://github.com/ashioyajotham/cot-faithfulness-mech-interp}
}
```

## ðŸŒŸ Acknowledgments

- **[Neel Nanda](https://www.neelnanda.io/)** - MATS stream supervisor and methodology guidance
- **[Anthropic](https://www.anthropic.com/)** - Attribution graphs methodology inspiration  
- **[TransformerLens](https://github.com/neelnanda-io/TransformerLens)** - Core interpretability toolkit
- **[MATS Program](https://www.matsprogram.org/)** - Research support and community

## ðŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
