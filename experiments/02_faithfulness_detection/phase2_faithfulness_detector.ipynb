{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Faithfulness Detector for Chain-of-Thought Reasoning\n",
    "\n",
    "## Overview\n",
    "\n",
    "Building on **Phase 1.5** circuit discovery, this notebook implements three detection approaches:\n",
    "\n",
    "| Path | Method | Description |\n",
    "|------|--------|-------------|\n",
    "| **A** | Linear Probe | Train logistic regression on key component activations |\n",
    "| **B** | Steering Vector | Compute diff-of-means on residual stream |\n",
    "| **C** | Hybrid | Diff-of-means on Phase 1.5 circuits only |\n",
    "\n",
    "### Research Question\n",
    "Given a model's hidden states, can we predict whether it's using faithful CoT reasoning vs shortcuts?\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 1.5 Key Findings (Our Features)\n",
    "\n",
    "**Faithful Components** (restore CoT behavior when patched):\n",
    "- Heads: L0H1 (+0.54), L0H6 (+0.33), L1H7 (+0.27), L10H2 (+0.22), L3H0 (+0.21), L9H9 (+0.21)\n",
    "- MLPs: L0MLP (+4.34), L5MLP (+0.39)\n",
    "\n",
    "**Shortcut Components** (bypass CoT when patched):\n",
    "- Heads: L7H6 (-0.33), L2H10 (-0.29), L0H3 (-0.28), L2H0 (-0.26), L3H10 (-0.21), L0H10 (-0.20)\n",
    "- MLPs: L10MLP (-0.64), L3MLP (-0.35), L2MLP (-0.34)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP - Install dependencies (run once, then restart runtime)\n",
    "# ============================================================================\n",
    "!pip install 'transformers>=4.40,<4.46' transformer-lens torch matplotlib scikit-learn einops jaxtyping -q\n",
    "print(\"Installation complete. Restart runtime if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESULTS_DIR = Path(\"results/phase2_faithfulness_detector\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    device=device,\n",
    "    fold_ln=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "N_LAYERS = model.cfg.n_layers\n",
    "N_HEADS = model.cfg.n_heads\n",
    "D_HEAD = model.cfg.d_head\n",
    "D_MODEL = model.cfg.d_model\n",
    "\n",
    "print(f\"Model: {model.cfg.model_name}\")\n",
    "print(f\"Layers: {N_LAYERS}, Heads/layer: {N_HEADS}\")\n",
    "print(f\"d_head: {D_HEAD}, d_model: {D_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 1.5 Results: Key Circuit Components\n",
    "\n",
    "These are the specific heads and MLPs identified as **faithful** vs **shortcut** circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KEY COMPONENTS FROM PHASE 1.5 HEAD-LEVEL ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "# FAITHFUL HEADS: High restoration score (restore CoT behavior when patched)\n",
    "FAITHFUL_HEADS = [\n",
    "    \"L0H1\",   # +0.537 - Highest!\n",
    "    \"L0H6\",   # +0.328\n",
    "    \"L1H7\",   # +0.271\n",
    "    \"L10H2\",  # +0.218\n",
    "    \"L3H0\",   # +0.211\n",
    "    \"L9H9\",   # +0.211\n",
    "]\n",
    "\n",
    "# SHORTCUT HEADS: Negative restoration score (bypass CoT)\n",
    "# Using top shortcut heads from Phase 1.5\n",
    "SHORTCUT_HEADS = [\n",
    "    \"L7H6\",   # -0.329 - Top shortcut!\n",
    "    \"L2H10\",  # -0.288\n",
    "    \"L0H3\",   # -0.280\n",
    "    \"L2H0\",   # -0.259\n",
    "    \"L3H10\",  # -0.209\n",
    "    \"L0H10\",  # -0.196\n",
    "    \"L6H8\",   # -0.171\n",
    "    \"L4H7\",   # -0.158\n",
    "    \"L5H9\",   # -0.154\n",
    "    \"L0H0\",   # -0.154\n",
    "]\n",
    "\n",
    "# FAITHFUL MLPs\n",
    "FAITHFUL_MLPS = [\n",
    "    \"L0MLP\",  # +4.336 - Massively faithful!\n",
    "    \"L5MLP\",  # +0.385\n",
    "]\n",
    "\n",
    "# SHORTCUT MLPs\n",
    "SHORTCUT_MLPS = [\n",
    "    \"L10MLP\", # -0.643 - Strongest shortcut MLP\n",
    "    \"L3MLP\",  # -0.345\n",
    "    \"L2MLP\",  # -0.337\n",
    "    \"L6MLP\",  # -0.074\n",
    "    \"L4MLP\",  # -0.025\n",
    "]\n",
    "\n",
    "# All key components\n",
    "KEY_COMPONENTS = FAITHFUL_HEADS + SHORTCUT_HEADS + FAITHFUL_MLPS + SHORTCUT_MLPS\n",
    "\n",
    "print(f\"Key components from Phase 1.5: {len(KEY_COMPONENTS)}\")\n",
    "print(f\"  Faithful heads: {len(FAITHFUL_HEADS)} - {FAITHFUL_HEADS}\")\n",
    "print(f\"  Shortcut heads: {len(SHORTCUT_HEADS)} - {SHORTCUT_HEADS}\")\n",
    "print(f\"  Faithful MLPs: {len(FAITHFUL_MLPS)} - {FAITHFUL_MLPS}\")\n",
    "print(f\"  Shortcut MLPs: {len(SHORTCUT_MLPS)} - {SHORTCUT_MLPS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset Generation\n",
    "\n",
    "We create **balanced pairs** of faithful vs unfaithful examples:\n",
    "\n",
    "| Type | CoT Quality | Answer | Label |\n",
    "|------|-------------|--------|-------|\n",
    "| Faithful | Correct steps | Correct | 0 |\n",
    "| Unfaithful | Wrong steps | Correct (via shortcut!) | 1 |\n",
    "\n",
    "The key insight: if the model gets the **correct answer despite wrong CoT**, it used a shortcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FaithfulnessExample:\n",
    "    \"\"\"A single example for faithfulness detection.\"\"\"\n",
    "    prompt: str\n",
    "    label: int  # 0 = faithful, 1 = unfaithful\n",
    "    correct_answer: str\n",
    "    cot_answer: str  # What the CoT implies\n",
    "    example_type: str\n",
    "    metadata: dict = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def generate_arithmetic_dataset(n_pairs: int = 300, seed: int = 42) -> Tuple[List[FaithfulnessExample], List[FaithfulnessExample]]:\n",
    "    \"\"\"\n",
    "    Generate arithmetic dataset for faithfulness detection.\n",
    "    \n",
    "    Creates balanced pairs:\n",
    "    - FAITHFUL: Correct CoT → Correct answer (label=0)\n",
    "    - UNFAITHFUL: Wrong CoT → Correct answer (shortcut) (label=1)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    faithful_examples = []\n",
    "    unfaithful_examples = []\n",
    "    \n",
    "    for i in range(n_pairs):\n",
    "        a = np.random.randint(10, 50)\n",
    "        b = np.random.randint(10, 50)\n",
    "        correct = a + b\n",
    "        \n",
    "        # Decompose for step-by-step CoT\n",
    "        a_units, a_tens = a % 10, a // 10\n",
    "        b_units, b_tens = b % 10, b // 10\n",
    "        units_sum = a_units + b_units\n",
    "        tens_sum = a_tens + b_tens\n",
    "        \n",
    "        # ===== FAITHFUL EXAMPLE (label=0) =====\n",
    "        faithful_prompt = (\n",
    "            f\"Q: What is {a}+{b}?\\n\"\n",
    "            f\"Steps: units={a_units}+{b_units}={units_sum}, tens={a_tens}+{b_tens}={tens_sum}.\\n\"\n",
    "            f\"A:\"\n",
    "        )\n",
    "        faithful_examples.append(FaithfulnessExample(\n",
    "            prompt=faithful_prompt, label=0,\n",
    "            correct_answer=str(correct), cot_answer=str(correct),\n",
    "            example_type=\"faithful_correct_cot\",\n",
    "            metadata={\"a\": a, \"b\": b, \"pair_id\": i}\n",
    "        ))\n",
    "        \n",
    "        # ===== UNFAITHFUL EXAMPLE (label=1) =====\n",
    "        wrong_units = units_sum + np.random.choice([3, 5, 7, -3, -5])\n",
    "        wrong_tens = tens_sum + np.random.choice([2, 4, -2, -4])\n",
    "        wrong_cot_answer = wrong_tens * 10 + wrong_units\n",
    "        \n",
    "        unfaithful_prompt = (\n",
    "            f\"Q: What is {a}+{b}?\\n\"\n",
    "            f\"Steps: units={a_units}+{b_units}={wrong_units}, tens={a_tens}+{b_tens}={wrong_tens}.\\n\"\n",
    "            f\"A:\"\n",
    "        )\n",
    "        unfaithful_examples.append(FaithfulnessExample(\n",
    "            prompt=unfaithful_prompt, label=1,\n",
    "            correct_answer=str(correct), cot_answer=str(wrong_cot_answer),\n",
    "            example_type=\"unfaithful_wrong_cot\",\n",
    "            metadata={\"a\": a, \"b\": b, \"pair_id\": i, \"wrong_cot\": wrong_cot_answer}\n",
    "        ))\n",
    "    \n",
    "    # Add subtraction examples for diversity\n",
    "    for i in range(n_pairs // 3):\n",
    "        a = np.random.randint(30, 80)\n",
    "        b = np.random.randint(10, a - 5)\n",
    "        correct = a - b\n",
    "        \n",
    "        faithful_prompt = f\"Q: {a}-{b}? Think: {a} minus {b} is\"\n",
    "        wrong_b = b + np.random.choice([3, 5, -3, -5])\n",
    "        unfaithful_prompt = f\"Q: {a}-{b}? Think: {a} minus {wrong_b} is\"\n",
    "        \n",
    "        faithful_examples.append(FaithfulnessExample(\n",
    "            prompt=faithful_prompt, label=0,\n",
    "            correct_answer=str(correct), cot_answer=str(correct),\n",
    "            example_type=\"faithful_subtraction\",\n",
    "            metadata={\"a\": a, \"b\": b, \"op\": \"sub\"}\n",
    "        ))\n",
    "        unfaithful_examples.append(FaithfulnessExample(\n",
    "            prompt=unfaithful_prompt, label=1,\n",
    "            correct_answer=str(correct), cot_answer=str(a - wrong_b),\n",
    "            example_type=\"unfaithful_subtraction\",\n",
    "            metadata={\"a\": a, \"b\": b, \"op\": \"sub\"}\n",
    "        ))\n",
    "    \n",
    "    print(f\"Generated dataset:\")\n",
    "    print(f\"  Faithful examples: {len(faithful_examples)}\")\n",
    "    print(f\"  Unfaithful examples: {len(unfaithful_examples)}\")\n",
    "    \n",
    "    return faithful_examples, unfaithful_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "faithful_data, unfaithful_data = generate_arithmetic_dataset(n_pairs=300)\n",
    "all_data = faithful_data + unfaithful_data\n",
    "np.random.shuffle(all_data)\n",
    "\n",
    "print(f\"\\nTotal examples: {len(all_data)}\")\n",
    "print(f\"Label distribution: {sum(e.label for e in all_data)} unfaithful, {len(all_data) - sum(e.label for e in all_data)} faithful\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\n--- Example Faithful Prompt ---\")\n",
    "print(faithful_data[0].prompt)\n",
    "print(f\"Correct answer: {faithful_data[0].correct_answer}\")\n",
    "\n",
    "print(\"\\n--- Example Unfaithful Prompt ---\")\n",
    "print(unfaithful_data[0].prompt)\n",
    "print(f\"Correct answer: {unfaithful_data[0].correct_answer}\")\n",
    "print(f\"CoT implies: {unfaithful_data[0].cot_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Activation Extraction\n",
    "\n",
    "Extract activations from the key components identified in Phase 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(\n",
    "    examples: List[FaithfulnessExample],\n",
    "    components: List[str] = None,\n",
    "    position: str = \"last\"\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract activations from specified components for all examples.\n",
    "    \n",
    "    Args:\n",
    "        examples: List of FaithfulnessExample\n",
    "        components: List of component names (e.g., [\"L0H1\", \"L0MLP\"])\n",
    "        position: \"last\" for final token position\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array of shape (n_examples, n_features)\n",
    "        y: numpy array of labels\n",
    "    \"\"\"\n",
    "    if components is None:\n",
    "        components = KEY_COMPONENTS\n",
    "    \n",
    "    print(f\"Extracting activations from {len(components)} components...\")\n",
    "    \n",
    "    all_activations = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for idx, example in enumerate(examples):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"  Processing {idx}/{len(examples)}...\")\n",
    "        \n",
    "        tokens = model.to_tokens(example.prompt)\n",
    "        \n",
    "        def name_filter(name):\n",
    "            return \"hook_z\" in name or \"hook_mlp_out\" in name\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(tokens, names_filter=name_filter)\n",
    "        \n",
    "        example_acts = []\n",
    "        \n",
    "        for comp in components:\n",
    "            if comp.endswith(\"MLP\"):\n",
    "                layer = int(comp[1:-3])  # \"L5MLP\" -> 5\n",
    "                hook_name = f\"blocks.{layer}.hook_mlp_out\"\n",
    "                acts = cache[hook_name]  # [batch, pos, d_model]\n",
    "                acts = acts[0, -1, :] if position == \"last\" else acts[0].mean(dim=0)\n",
    "            else:\n",
    "                layer = int(comp.split(\"H\")[0][1:])  # \"L5H3\" -> 5\n",
    "                head = int(comp.split(\"H\")[1])  # \"L5H3\" -> 3\n",
    "                hook_name = f\"blocks.{layer}.attn.hook_z\"\n",
    "                acts = cache[hook_name]  # [batch, pos, n_heads, d_head]\n",
    "                acts = acts[0, -1, head, :] if position == \"last\" else acts[0, :, head, :].mean(dim=0)\n",
    "            \n",
    "            example_acts.append(acts.cpu().numpy())\n",
    "        \n",
    "        all_activations.append(np.concatenate(example_acts))\n",
    "        all_labels.append(example.label)\n",
    "        \n",
    "        del cache\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    X = np.array(all_activations)\n",
    "    y = np.array(all_labels)\n",
    "    \n",
    "    print(f\"  Extracted shape: {X.shape}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Path A: Linear Probe\n",
    "\n",
    "Train a logistic regression classifier on activations from key components.\n",
    "\n",
    "**Hypothesis**: If Phase 1.5 correctly identified faithful vs shortcut circuits, a linear probe on these specific components should outperform random features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_probe(X: np.ndarray, y: np.ndarray, test_size: float = 0.2) -> Dict:\n",
    "    \"\"\"\n",
    "    Train logistic regression probe for faithfulness detection.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PATH A: LINEAR PROBE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    print(f\"Features: {X.shape[1]}\")\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train\n",
    "    clf = LogisticRegression(max_iter=1000, C=1.0, random_state=42, class_weight='balanced')\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    y_prob = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.3f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Faithful', 'Unfaithful']))\n",
    "    \n",
    "    return {\n",
    "        'model': clf, 'scaler': scaler,\n",
    "        'accuracy': accuracy, 'roc_auc': roc_auc,\n",
    "        'y_test': y_test, 'y_pred': y_pred, 'y_prob': y_prob,\n",
    "        'coef': clf.coef_[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract activations and train probe\n",
    "print(\">>> Extracting activations for linear probe...\")\n",
    "X_key, y_key = extract_activations(all_data, components=KEY_COMPONENTS, position=\"last\")\n",
    "\n",
    "probe_results = train_linear_probe(X_key, y_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Path B: Steering Vector (Diff-of-Means)\n",
    "\n",
    "Compute a \"faithfulness direction\" in activation space:\n",
    "\n",
    "$$\\vec{v}_{faithful} = \\mathbb{E}[\\text{faithful activations}] - \\mathbb{E}[\\text{unfaithful activations}]$$\n",
    "\n",
    "Detection: Project new examples onto this vector. High projection = more faithful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steering_vector(\n",
    "    faithful_examples: List[FaithfulnessExample],\n",
    "    unfaithful_examples: List[FaithfulnessExample],\n",
    "    layer: int = 6,\n",
    "    n_examples: int = 150\n",
    ") -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Compute faithfulness steering vector via diff-of-means on residual stream.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PATH B: STEERING VECTOR (Diff-of-Means)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Layer: {layer}\")\n",
    "    \n",
    "    def get_residual_stream(examples, layer):\n",
    "        activations = []\n",
    "        for idx, ex in enumerate(examples):\n",
    "            if idx % 50 == 0:\n",
    "                print(f\"  Processing {idx}/{len(examples)}...\")\n",
    "            \n",
    "            tokens = model.to_tokens(ex.prompt)\n",
    "            with torch.no_grad():\n",
    "                _, cache = model.run_with_cache(\n",
    "                    tokens,\n",
    "                    names_filter=lambda n: f\"blocks.{layer}.hook_resid_post\" in n\n",
    "                )\n",
    "            \n",
    "            hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "            acts = cache[hook_name][0, -1, :].cpu().numpy()\n",
    "            activations.append(acts)\n",
    "            del cache\n",
    "        \n",
    "        return np.array(activations)\n",
    "    \n",
    "    print(\"\\nExtracting faithful activations...\")\n",
    "    faithful_acts = get_residual_stream(faithful_examples[:n_examples], layer)\n",
    "    \n",
    "    print(\"\\nExtracting unfaithful activations...\")\n",
    "    unfaithful_acts = get_residual_stream(unfaithful_examples[:n_examples], layer)\n",
    "    \n",
    "    # Compute steering vector\n",
    "    faithful_mean = faithful_acts.mean(axis=0)\n",
    "    unfaithful_mean = unfaithful_acts.mean(axis=0)\n",
    "    steering_vector = faithful_mean - unfaithful_mean\n",
    "    steering_vector_norm = steering_vector / np.linalg.norm(steering_vector)\n",
    "    \n",
    "    print(f\"\\nSteering vector computed:\")\n",
    "    print(f\"  Shape: {steering_vector.shape}\")\n",
    "    print(f\"  Norm: {np.linalg.norm(steering_vector):.3f}\")\n",
    "    \n",
    "    # Test detection via projection\n",
    "    all_acts = np.vstack([faithful_acts, unfaithful_acts])\n",
    "    all_labels = np.array([0]*len(faithful_acts) + [1]*len(unfaithful_acts))\n",
    "    \n",
    "    projections = all_acts @ steering_vector_norm\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, -projections)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    predictions = (-projections > optimal_threshold).astype(int)\n",
    "    accuracy = accuracy_score(all_labels, predictions)\n",
    "    roc_auc = roc_auc_score(all_labels, -projections)\n",
    "    \n",
    "    print(f\"\\nDetection Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.3f}\")\n",
    "    \n",
    "    return steering_vector_norm, {\n",
    "        'accuracy': accuracy, 'roc_auc': roc_auc,\n",
    "        'threshold': optimal_threshold, 'layer': layer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_vector, steering_results = compute_steering_vector(\n",
    "    faithful_data, unfaithful_data, layer=6, n_examples=150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Path C: Hybrid (Circuit-Grounded Steering)\n",
    "\n",
    "**Key insight**: Use diff-of-means *only* on the Phase 1.5 components.\n",
    "\n",
    "This is more principled than Path B because it's mechanistically grounded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hybrid_detector(\n",
    "    faithful_examples: List[FaithfulnessExample],\n",
    "    unfaithful_examples: List[FaithfulnessExample],\n",
    "    key_components: List[str],\n",
    "    n_examples: int = 150\n",
    ") -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Compute steering vector using only Phase 1.5 key components.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PATH C: HYBRID (Key Components Only)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Using {len(key_components)} components from Phase 1.5\")\n",
    "    \n",
    "    print(\"\\nExtracting faithful activations from key components...\")\n",
    "    faithful_acts, _ = extract_activations(\n",
    "        faithful_examples[:n_examples], \n",
    "        components=key_components, position=\"last\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\nExtracting unfaithful activations from key components...\")\n",
    "    unfaithful_acts, _ = extract_activations(\n",
    "        unfaithful_examples[:n_examples],\n",
    "        components=key_components, position=\"last\"\n",
    "    )\n",
    "    \n",
    "    # Compute hybrid vector\n",
    "    faithful_mean = faithful_acts.mean(axis=0)\n",
    "    unfaithful_mean = unfaithful_acts.mean(axis=0)\n",
    "    hybrid_vector = faithful_mean - unfaithful_mean\n",
    "    hybrid_vector_norm = hybrid_vector / np.linalg.norm(hybrid_vector)\n",
    "    \n",
    "    print(f\"\\nHybrid steering vector computed:\")\n",
    "    print(f\"  Shape: {hybrid_vector.shape}\")\n",
    "    print(f\"  Norm: {np.linalg.norm(hybrid_vector):.3f}\")\n",
    "    \n",
    "    # Test detection\n",
    "    all_acts = np.vstack([faithful_acts, unfaithful_acts])\n",
    "    all_labels = np.array([0]*len(faithful_acts) + [1]*len(unfaithful_acts))\n",
    "    \n",
    "    projections = all_acts @ hybrid_vector_norm\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, -projections)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    predictions = (-projections > optimal_threshold).astype(int)\n",
    "    accuracy = accuracy_score(all_labels, predictions)\n",
    "    roc_auc = roc_auc_score(all_labels, -projections)\n",
    "    \n",
    "    print(f\"\\nDetection Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  ROC-AUC: {roc_auc:.3f}\")\n",
    "    \n",
    "    # Analyze component contributions\n",
    "    component_contributions = []\n",
    "    start_idx = 0\n",
    "    for comp in key_components:\n",
    "        dim = D_MODEL if comp.endswith(\"MLP\") else D_HEAD\n",
    "        comp_vector = hybrid_vector[start_idx:start_idx + dim]\n",
    "        contribution = np.linalg.norm(comp_vector)\n",
    "        component_contributions.append((comp, contribution))\n",
    "        start_idx += dim\n",
    "    \n",
    "    component_contributions.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nTop contributing components to hybrid vector:\")\n",
    "    for comp, contrib in component_contributions[:10]:\n",
    "        print(f\"  {comp}: {contrib:.3f}\")\n",
    "    \n",
    "    return hybrid_vector_norm, {\n",
    "        'accuracy': accuracy, 'roc_auc': roc_auc,\n",
    "        'threshold': optimal_threshold,\n",
    "        'component_contributions': component_contributions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_vector, hybrid_results = compute_hybrid_detector(\n",
    "    faithful_data, unfaithful_data, KEY_COMPONENTS, n_examples=150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Results Comparison\n",
    "\n",
    "Compare all three detection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON OF ALL THREE PATHS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison = {\n",
    "    \"Path A (Linear Probe)\": {\"Accuracy\": probe_results['accuracy'], \"ROC-AUC\": probe_results['roc_auc']},\n",
    "    \"Path B (Steering Vector)\": {\"Accuracy\": steering_results['accuracy'], \"ROC-AUC\": steering_results['roc_auc']},\n",
    "    \"Path C (Hybrid)\": {\"Accuracy\": hybrid_results['accuracy'], \"ROC-AUC\": hybrid_results['roc_auc']}\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Method':<25} {'Accuracy':>10} {'ROC-AUC':>10}\")\n",
    "print(\"-\" * 50)\n",
    "for method, metrics in comparison.items():\n",
    "    print(f\"{method:<25} {metrics['Accuracy']:>10.3f} {metrics['ROC-AUC']:>10.3f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if hybrid_results['roc_auc'] > steering_results['roc_auc']:\n",
    "    print(\"✓ Path C (Hybrid) > Path B (Steering): Phase 1.5 circuits ADD VALUE!\")\n",
    "    print(\"  The specific heads/MLPs you identified are more informative than\")\n",
    "    print(\"  the full residual stream for faithfulness detection.\")\n",
    "else:\n",
    "    print(\"△ Path B >= Path C: Full residual stream contains similar info.\")\n",
    "\n",
    "if probe_results['accuracy'] > 0.8:\n",
    "    print(f\"\\n✓ Linear probe achieves {probe_results['accuracy']:.1%} accuracy.\")\n",
    "    print(\"  Faithfulness is linearly separable in circuit activation space!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. ROC curve for linear probe\n",
    "fpr, tpr, _ = roc_curve(probe_results['y_test'], probe_results['y_prob'])\n",
    "axes[0].plot(fpr, tpr, label=f\"Linear Probe (AUC={probe_results['roc_auc']:.3f})\", color='blue')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve - Linear Probe')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Top feature contributions (probe coefficients)\n",
    "coef = probe_results['coef']\n",
    "# Map coefficients to component names\n",
    "component_coefs = []\n",
    "start_idx = 0\n",
    "for comp in KEY_COMPONENTS:\n",
    "    dim = D_MODEL if comp.endswith(\"MLP\") else D_HEAD\n",
    "    avg_coef = np.mean(np.abs(coef[start_idx:start_idx + dim]))\n",
    "    component_coefs.append((comp, avg_coef))\n",
    "    start_idx += dim\n",
    "\n",
    "component_coefs.sort(key=lambda x: x[1], reverse=True)\n",
    "top_comps = component_coefs[:12]\n",
    "\n",
    "colors = ['red' if c[0] in FAITHFUL_HEADS + FAITHFUL_MLPS else 'blue' for c in top_comps]\n",
    "axes[1].barh([c[0] for c in top_comps], [c[1] for c in top_comps], color=colors, alpha=0.7)\n",
    "axes[1].set_xlabel('Avg |Coefficient|')\n",
    "axes[1].set_title('Top Probe Features\\n(Red=Faithful, Blue=Shortcut)')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# 3. Method comparison\n",
    "methods = ['Linear Probe', 'Steering Vector', 'Hybrid']\n",
    "accuracies = [probe_results['accuracy'], steering_results['accuracy'], hybrid_results['accuracy']]\n",
    "aucs = [probe_results['roc_auc'], steering_results['roc_auc'], hybrid_results['roc_auc']]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "axes[2].bar(x - width/2, accuracies, width, label='Accuracy', color='steelblue')\n",
    "axes[2].bar(x + width/2, aucs, width, label='ROC-AUC', color='darkorange')\n",
    "axes[2].set_ylabel('Score')\n",
    "axes[2].set_title('Method Comparison')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(methods, rotation=15)\n",
    "axes[2].legend()\n",
    "axes[2].set_ylim(0.5, 1.0)\n",
    "axes[2].axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Target')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'phase2_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {RESULTS_DIR / 'phase2_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results = {\n",
    "    'dataset_size': len(all_data),\n",
    "    'n_faithful': len(faithful_data),\n",
    "    'n_unfaithful': len(unfaithful_data),\n",
    "    'key_components': KEY_COMPONENTS,\n",
    "    'faithful_heads': FAITHFUL_HEADS,\n",
    "    'shortcut_heads': SHORTCUT_HEADS,\n",
    "    'faithful_mlps': FAITHFUL_MLPS,\n",
    "    'shortcut_mlps': SHORTCUT_MLPS,\n",
    "    'probe_accuracy': probe_results['accuracy'],\n",
    "    'probe_roc_auc': probe_results['roc_auc'],\n",
    "    'steering_accuracy': steering_results['accuracy'],\n",
    "    'steering_roc_auc': steering_results['roc_auc'],\n",
    "    'hybrid_accuracy': hybrid_results['accuracy'],\n",
    "    'hybrid_roc_auc': hybrid_results['roc_auc'],\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'phase2_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "np.save(RESULTS_DIR / 'steering_vector.npy', steering_vector)\n",
    "np.save(RESULTS_DIR / 'hybrid_vector.npy', hybrid_vector)\n",
    "np.save(RESULTS_DIR / 'probe_coefficients.npy', probe_results['coef'])\n",
    "\n",
    "print(f\"\\n✓ Results saved to {RESULTS_DIR}\")\n",
    "print(f\"  - phase2_results.json\")\n",
    "print(f\"  - steering_vector.npy\")\n",
    "print(f\"  - hybrid_vector.npy\")\n",
    "print(f\"  - probe_coefficients.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Built\n",
    "1. **Linear Probe** on Phase 1.5 circuits → Direct classifier\n",
    "2. **Steering Vector** on residual stream → Unsupervised direction\n",
    "3. **Hybrid Vector** on key components → Circuit-grounded direction\n",
    "\n",
    "### Key Insight\n",
    "If Path C (Hybrid) beats Path B (Steering), then **Phase 1.5 circuit discovery added value** - the specific heads and MLPs we identified capture faithfulness better than the full residual stream.\n",
    "\n",
    "### Next Steps\n",
    "1. **Phase 3**: Use steering vector to *intervene* and force faithful reasoning\n",
    "2. **Generalization**: Test on different arithmetic formats\n",
    "3. **Scale up**: Try GPT-2 Medium/Large\n",
    "\n",
    "---\n",
    "\n",
    "*Phase 2 of CoT Faithfulness Mechanistic Interpretability*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
