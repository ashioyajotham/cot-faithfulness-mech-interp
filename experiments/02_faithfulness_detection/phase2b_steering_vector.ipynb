{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2B: Steering Vectors for Faithfulness Detection & Intervention\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements **Path B**: using diff-of-means to compute a **faithfulness direction** in activation space.\n",
    "\n",
    "### Key Insight: Diff-of-Means Has TWO Uses\n",
    "\n",
    "```\n",
    "                    Diff-of-Means Vector\n",
    "                           \u2502\n",
    "           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "           \u2502                               \u2502\n",
    "      DETECTION                      INTERVENTION\n",
    "   Project onto vector \u2192           Add vector during\n",
    "   threshold \u2192 classify            inference \u2192 change\n",
    "                                   model behavior\n",
    "```\n",
    "\n",
    "### References\n",
    "- **Anthropic's Persona Vectors** (arXiv:2507.21509): diff-of-means for monitoring & steering\n",
    "- **CAA** (Rimsky et al., 2024): Contrastive Activation Addition for sycophancy, corrigibility\n",
    "\n",
    "*Author: Victor Ashioya | CoT Faithfulness Mech Interp*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install 'transformers>=4.40,<4.46' transformer-lens torch matplotlib scikit-learn einops jaxtyping -q\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# Configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESULTS_DIR = Path(\"results/phase2b_steering_vector\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Loading GPT-2 Small...\")\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    device=device,\n",
    "    fold_ln=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "N_LAYERS = model.cfg.n_layers\n",
    "N_HEADS = model.cfg.n_heads\n",
    "D_HEAD = model.cfg.d_head\n",
    "D_MODEL = model.cfg.d_model\n",
    "\n",
    "print(f\"Model: {model.cfg.model_name}\")\n",
    "print(f\"Architecture: {N_LAYERS} layers, d_model={D_MODEL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class FaithfulnessExample:\n",
    "    \"\"\"A single example for faithfulness detection.\"\"\"\n",
    "    prompt: str\n",
    "    label: int  # 0 = faithful, 1 = unfaithful\n",
    "    correct_answer: str\n",
    "    cot_answer: str\n",
    "    example_type: str\n",
    "    metadata: dict = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def generate_arithmetic_dataset(n_pairs: int = 400, seed: int = 42) -> Tuple[List, List]:\n",
    "    \"\"\"Generate balanced dataset for faithfulness detection.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    faithful, unfaithful = [], []\n",
    "    \n",
    "    for i in range(n_pairs):\n",
    "        a = np.random.randint(10, 50)\n",
    "        b = np.random.randint(10, 50)\n",
    "        correct = a + b\n",
    "        \n",
    "        a_units, a_tens = a % 10, a // 10\n",
    "        b_units, b_tens = b % 10, b // 10\n",
    "        units_sum = a_units + b_units\n",
    "        tens_sum = a_tens + b_tens\n",
    "        \n",
    "        # FAITHFUL\n",
    "        faithful_prompt = (\n",
    "            f\"Q: What is {a}+{b}?\\n\"\n",
    "            f\"Steps: units={a_units}+{b_units}={units_sum}, tens={a_tens}+{b_tens}={tens_sum}.\\n\"\n",
    "            f\"A:\"\n",
    "        )\n",
    "        faithful.append(FaithfulnessExample(\n",
    "            prompt=faithful_prompt,\n",
    "            label=0,\n",
    "            correct_answer=str(correct),\n",
    "            cot_answer=str(correct),\n",
    "            example_type=\"faithful_addition\",\n",
    "            metadata={\"a\": a, \"b\": b, \"pair_id\": i}\n",
    "        ))\n",
    "        \n",
    "        # UNFAITHFUL\n",
    "        wrong_units = units_sum + np.random.choice([3, 5, 7, -3, -5])\n",
    "        wrong_tens = tens_sum + np.random.choice([2, 4, -2, -4])\n",
    "        wrong_cot_answer = wrong_tens * 10 + wrong_units\n",
    "        \n",
    "        unfaithful_prompt = (\n",
    "            f\"Q: What is {a}+{b}?\\n\"\n",
    "            f\"Steps: units={a_units}+{b_units}={wrong_units}, tens={a_tens}+{b_tens}={wrong_tens}.\\n\"\n",
    "            f\"A:\"\n",
    "        )\n",
    "        unfaithful.append(FaithfulnessExample(\n",
    "            prompt=unfaithful_prompt,\n",
    "            label=1,\n",
    "            correct_answer=str(correct),\n",
    "            cot_answer=str(wrong_cot_answer),\n",
    "            example_type=\"unfaithful_addition\",\n",
    "            metadata={\"a\": a, \"b\": b, \"pair_id\": i, \"wrong_answer\": wrong_cot_answer}\n",
    "        ))\n",
    "    \n",
    "    return faithful, unfaithful\n",
    "\n",
    "\n",
    "# Generate dataset\n",
    "faithful_data, unfaithful_data = generate_arithmetic_dataset(n_pairs=400)\n",
    "print(f\"Generated {len(faithful_data)} faithful + {len(unfaithful_data)} unfaithful examples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Part 1: Compute Steering Vector (Diff-of-Means)\n",
    "\n",
    "The steering vector is:\n",
    "\n",
    "$$\\vec{v} = \\mathbb{E}[\\text{faithful acts}] - \\mathbb{E}[\\text{unfaithful acts}]$$\n",
    "\n",
    "This gives a direction pointing from \"unfaithful\" toward \"faithful\" reasoning.\n",
    "We extract from residual stream at **layer 6** (middle layer, following CAA methodology).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "STEERING_LAYER = 6  # Middle layer - where most processing happens\n",
    "\n",
    "\n",
    "def extract_residual_stream(examples: List[FaithfulnessExample], layer: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract residual stream activations at specified layer.\n",
    "    \n",
    "    Args:\n",
    "        examples: List of FaithfulnessExample\n",
    "        layer: Which layer's residual stream to extract\n",
    "    \n",
    "    Returns:\n",
    "        activations: (n_examples, d_model) array\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    \n",
    "    for idx, example in enumerate(examples):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"  Processing {idx}/{len(examples)}...\")\n",
    "        \n",
    "        tokens = model.to_tokens(example.prompt)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(\n",
    "                tokens,\n",
    "                names_filter=lambda n: f\"blocks.{layer}.hook_resid_post\" in n\n",
    "            )\n",
    "        \n",
    "        # Get residual stream at final token position\n",
    "        hook_name = f\"blocks.{layer}.hook_resid_post\"\n",
    "        acts = cache[hook_name][0, -1, :].cpu().numpy()\n",
    "        activations.append(acts)\n",
    "        \n",
    "        del cache\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return np.array(activations)\n",
    "\n",
    "\n",
    "print(f\"\\nExtracting residual stream at layer {STEERING_LAYER}...\")\n",
    "print(\"Processing faithful examples...\")\n",
    "faithful_acts = extract_residual_stream(faithful_data[:200], STEERING_LAYER)  # Use 200 for mean\n",
    "print(\"Processing unfaithful examples...\")\n",
    "unfaithful_acts = extract_residual_stream(unfaithful_data[:200], STEERING_LAYER)\n",
    "\n",
    "# Compute steering vector\n",
    "faithful_mean = faithful_acts.mean(axis=0)\n",
    "unfaithful_mean = unfaithful_acts.mean(axis=0)\n",
    "steering_vector = faithful_mean - unfaithful_mean\n",
    "\n",
    "# Normalize for later use\n",
    "steering_vector_normalized = steering_vector / np.linalg.norm(steering_vector)\n",
    "\n",
    "print(f\"\\nSteering vector computed!\")\n",
    "print(f\"  Shape: {steering_vector.shape}\")\n",
    "print(f\"  Norm: {np.linalg.norm(steering_vector):.4f}\")\n",
    "print(f\"  Max component: {np.max(np.abs(steering_vector)):.4f}\")\n",
    "\n",
    "# Save steering vector\n",
    "np.save(RESULTS_DIR / 'steering_vector.npy', steering_vector)\n",
    "np.save(RESULTS_DIR / 'steering_vector_normalized.npy', steering_vector_normalized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Part 2: Detection via Projection\n",
    "\n",
    "Project each example onto the steering vector:\n",
    "- **High projection** \u2192 predict \"faithful\"\n",
    "- **Low projection** \u2192 predict \"unfaithful\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PART 2: DETECTION VIA PROJECTION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "\"\"\"\n",
    "For DETECTION, we project each example onto the steering vector:\n",
    "\n",
    "    score = activation \u00b7 steering_vector_normalized\n",
    "\n",
    "If score > threshold \u2192 predict \"faithful\"\n",
    "If score < threshold \u2192 predict \"unfaithful\"\n",
    "\"\"\"\n",
    "\n",
    "# Extract test set activations\n",
    "print(\"\\nExtracting test set activations...\")\n",
    "test_faithful = faithful_data[200:400]  # Held out from mean computation\n",
    "test_unfaithful = unfaithful_data[200:400]\n",
    "\n",
    "test_faithful_acts = extract_residual_stream(test_faithful, STEERING_LAYER)\n",
    "test_unfaithful_acts = extract_residual_stream(test_unfaithful, STEERING_LAYER)\n",
    "\n",
    "# Compute projection scores\n",
    "faithful_scores = test_faithful_acts @ steering_vector_normalized\n",
    "unfaithful_scores = test_unfaithful_acts @ steering_vector_normalized\n",
    "\n",
    "all_scores = np.concatenate([faithful_scores, unfaithful_scores])\n",
    "all_labels = np.array([0]*len(faithful_scores) + [1]*len(unfaithful_scores))\n",
    "\n",
    "print(f\"\\nProjection score statistics:\")\n",
    "print(f\"  Faithful mean:   {faithful_scores.mean():.4f} \u00b1 {faithful_scores.std():.4f}\")\n",
    "print(f\"  Unfaithful mean: {unfaithful_scores.mean():.4f} \u00b1 {unfaithful_scores.std():.4f}\")\n",
    "print(f\"  Separation: {faithful_scores.mean() - unfaithful_scores.mean():.4f}\")\n",
    "\n",
    "# Find optimal threshold via ROC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, -all_scores)  # Negative because lower = unfaithful\n",
    "roc_auc = roc_auc_score(all_labels, -all_scores)\n",
    "\n",
    "# Find threshold that maximizes accuracy\n",
    "best_acc = 0\n",
    "best_threshold = 0\n",
    "for thresh in thresholds:\n",
    "    preds = (-all_scores > thresh).astype(int)\n",
    "    acc = accuracy_score(all_labels, preds)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"\\nDetection Results:\")\n",
    "print(f\"  ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"  Best Accuracy: {best_acc:.3f}\")\n",
    "print(f\"  Optimal Threshold: {-best_threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Part 3: Intervention \u2014 Steering Toward Faithfulness\n",
    "\n",
    "The exciting part! Add the steering vector during inference:\n",
    "\n",
    "$$\\text{residual}_{\\text{new}} = \\text{residual}_{\\text{old}} + \\alpha \\cdot \\vec{v}_{\\text{faithful}}$$\n",
    "\n",
    "**Hypothesis:** Adding $\\vec{v}_{\\text{faithful}}$ on unfaithful examples should make the model follow the (wrong) CoT.\n",
    "This would **decrease accuracy** but **increase faithfulness** \u2014 proving the vector captures a real direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_with_steering(\n",
    "    prompt: str,\n",
    "    steering_vec: np.ndarray,\n",
    "    layer: int,\n",
    "    alpha: float = 1.0\n",
    ") -> Tuple[str, List[Tuple[str, float]]]:\n",
    "    \"\"\"\n",
    "    Run model with steering vector added at specified layer.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Input prompt\n",
    "        steering_vec: Direction to add (d_model,)\n",
    "        layer: Which layer to intervene at\n",
    "        alpha: Steering strength (can be negative to steer opposite direction)\n",
    "    \n",
    "    Returns:\n",
    "        generated_text: Model's completion\n",
    "        top_tokens: List of (token, probability) for top predictions\n",
    "    \"\"\"\n",
    "    tokens = model.to_tokens(prompt)\n",
    "    steering_tensor = torch.tensor(steering_vec, dtype=torch.float32, device=device)\n",
    "    \n",
    "    def steering_hook(resid, hook):\n",
    "        # Add steering vector at final token position\n",
    "        resid[:, -1, :] += alpha * steering_tensor\n",
    "        return resid\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model.run_with_hooks(\n",
    "            tokens,\n",
    "            fwd_hooks=[(f\"blocks.{layer}.hook_resid_post\", steering_hook)]\n",
    "        )\n",
    "    \n",
    "    # Get top predictions\n",
    "    probs = torch.softmax(logits[0, -1, :], dim=-1)\n",
    "    top_probs, top_indices = torch.topk(probs, 10)\n",
    "    \n",
    "    top_tokens = []\n",
    "    for prob, idx in zip(top_probs, top_indices):\n",
    "        token_str = model.tokenizer.decode([idx.item()])\n",
    "        top_tokens.append((token_str, prob.item()))\n",
    "    \n",
    "    # Generate answer\n",
    "    predicted_token = model.tokenizer.decode([top_indices[0].item()])\n",
    "    \n",
    "    return predicted_token, top_tokens\n",
    "\n",
    "\n",
    "def evaluate_intervention(\n",
    "    examples: List[FaithfulnessExample],\n",
    "    steering_vec: np.ndarray,\n",
    "    layer: int,\n",
    "    alpha: float\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate intervention effect on a set of examples.\n",
    "    \n",
    "    Returns metrics on:\n",
    "    - Accuracy (does model get correct answer?)\n",
    "    - Faithfulness (does model follow CoT?)\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'correct_count': 0,\n",
    "        'follows_cot_count': 0,\n",
    "        'total': len(examples),\n",
    "        'examples': []\n",
    "    }\n",
    "    \n",
    "    for example in examples:\n",
    "        pred_token, top_tokens = run_with_steering(\n",
    "            example.prompt, steering_vec, layer, alpha\n",
    "        )\n",
    "        \n",
    "        # Check if prediction matches correct answer\n",
    "        is_correct = example.correct_answer in pred_token or pred_token.strip() == example.correct_answer\n",
    "        \n",
    "        # Check if prediction matches CoT answer (what CoT says the answer should be)\n",
    "        follows_cot = example.cot_answer in pred_token or pred_token.strip() == example.cot_answer\n",
    "        \n",
    "        if is_correct:\n",
    "            results['correct_count'] += 1\n",
    "        if follows_cot:\n",
    "            results['follows_cot_count'] += 1\n",
    "        \n",
    "        results['examples'].append({\n",
    "            'prompt': example.prompt[:50] + '...',\n",
    "            'predicted': pred_token,\n",
    "            'correct': example.correct_answer,\n",
    "            'cot_answer': example.cot_answer,\n",
    "            'is_correct': is_correct,\n",
    "            'follows_cot': follows_cot\n",
    "        })\n",
    "    \n",
    "    results['accuracy'] = results['correct_count'] / results['total']\n",
    "    results['faithfulness'] = results['follows_cot_count'] / results['total']\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Test baseline (no intervention)\n",
    "print(\"\\nBaseline (no intervention):\")\n",
    "baseline_results = evaluate_intervention(\n",
    "    unfaithful_data[:50], steering_vector, STEERING_LAYER, alpha=0.0\n",
    ")\n",
    "print(f\"  Accuracy: {baseline_results['accuracy']:.1%}\")\n",
    "print(f\"  Faithfulness: {baseline_results['faithfulness']:.1%}\")\n",
    "\n",
    "# Test different steering strengths\n",
    "print(\"\\nTesting intervention strengths...\")\n",
    "alphas = [0.0, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "intervention_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\n  \u03b1 = {alpha}:\")\n",
    "    results = evaluate_intervention(\n",
    "        unfaithful_data[:50], steering_vector, STEERING_LAYER, alpha\n",
    "    )\n",
    "    intervention_results.append({\n",
    "        'alpha': alpha,\n",
    "        'accuracy': results['accuracy'],\n",
    "        'faithfulness': results['faithfulness']\n",
    "    })\n",
    "    print(f\"    Accuracy:    {results['accuracy']:.1%}\")\n",
    "    print(f\"    Faithfulness: {results['faithfulness']:.1%}\")\n",
    "\n",
    "# Also test NEGATIVE steering (toward unfaithfulness)\n",
    "print(\"\\n  Testing negative steering (toward unfaithfulness):\")\n",
    "for alpha in [-1.0, -2.0]:\n",
    "    results = evaluate_intervention(\n",
    "        faithful_data[:50], steering_vector, STEERING_LAYER, alpha\n",
    "    )\n",
    "    print(f\"  \u03b1 = {alpha}: Accuracy={results['accuracy']:.1%}, Faithfulness={results['faithfulness']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Score Distribution\n",
    "axes[0, 0].hist(faithful_scores, bins=30, alpha=0.7, label='Faithful', color='green')\n",
    "axes[0, 0].hist(unfaithful_scores, bins=30, alpha=0.7, label='Unfaithful', color='red')\n",
    "axes[0, 0].axvline(x=-best_threshold, color='black', linestyle='--', label=f'Threshold')\n",
    "axes[0, 0].set_xlabel('Projection onto Steering Vector')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Detection: Score Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. ROC Curve\n",
    "axes[0, 1].plot(fpr, tpr, 'b-', linewidth=2, label=f'Steering Vector (AUC={roc_auc:.3f})')\n",
    "axes[0, 1].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "axes[0, 1].set_xlabel('False Positive Rate')\n",
    "axes[0, 1].set_ylabel('True Positive Rate')\n",
    "axes[0, 1].set_title('Detection: ROC Curve')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Intervention Effect\n",
    "alphas_plot = [r['alpha'] for r in intervention_results]\n",
    "accs = [r['accuracy'] for r in intervention_results]\n",
    "faiths = [r['faithfulness'] for r in intervention_results]\n",
    "\n",
    "axes[1, 0].plot(alphas_plot, accs, 'b-o', linewidth=2, label='Accuracy', markersize=8)\n",
    "axes[1, 0].plot(alphas_plot, faiths, 'g-s', linewidth=2, label='Faithfulness', markersize=8)\n",
    "axes[1, 0].set_xlabel('Steering Strength (\u03b1)')\n",
    "axes[1, 0].set_ylabel('Rate')\n",
    "axes[1, 0].set_title('Intervention: Effect of Steering Strength')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim(0, 1.1)\n",
    "\n",
    "# 4. Steering Vector Components\n",
    "axes[1, 1].bar(range(len(steering_vector)), steering_vector, width=1.0, alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Dimension')\n",
    "axes[1, 1].set_ylabel('Value')\n",
    "axes[1, 1].set_title(f'Steering Vector Components (Layer {STEERING_LAYER})')\n",
    "axes[1, 1].axhline(y=0, color='black', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'phase2b_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved visualization: {RESULTS_DIR / 'phase2b_results.png'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = {\n",
    "    'detection': {\n",
    "        'roc_auc': roc_auc,\n",
    "        'best_accuracy': best_acc,\n",
    "        'optimal_threshold': float(-best_threshold),\n",
    "        'faithful_mean_score': float(faithful_scores.mean()),\n",
    "        'unfaithful_mean_score': float(unfaithful_scores.mean()),\n",
    "    },\n",
    "    'intervention': intervention_results,\n",
    "    'steering_layer': STEERING_LAYER,\n",
    "    'steering_vector_norm': float(np.linalg.norm(steering_vector)),\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'phase2b_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PHASE 2B COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Detection:\")\n",
    "print(f\"  \u2713 ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"  \u2713 Best Accuracy: {best_acc:.1%}\")\n",
    "print(f\"\\nIntervention:\")\n",
    "print(f\"  \u2713 Baseline accuracy: {baseline_results['accuracy']:.1%}\")\n",
    "print(f\"  \u2713 Tested {len(alphas)} steering strengths\")\n",
    "print(f\"\\n\u2713 Results saved to {RESULTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interpretation\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Detection**: Steering vector achieves ~72% accuracy (worse than probe at 88%)\n",
    "   - Diff-of-means can't learn weighted combinations\n",
    "\n",
    "2. **Intervention Effect**:\n",
    "   - \u03b1=0: Model uses shortcuts, gets correct answer\n",
    "   - As \u03b1\u2191: Model increasingly follows CoT\n",
    "   - High \u03b1: More faithful but LESS accurate (expected! CoT is wrong)\n",
    "\n",
    "3. **Causal Evidence**: Intervention working = **causal proof** that the steering vector captures a real faithfulness direction\n",
    "\n",
    "### Comparison with Anthropic Persona Vectors\n",
    "Same technique, different domain:\n",
    "- Anthropic: helpful/harmful personas \u2192 steer away from harm\n",
    "- Us: faithful/unfaithful reasoning \u2192 steer toward following CoT\n",
    "\n",
    "*Phase 2B | Victor Ashioya | Bluedot Impact*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}